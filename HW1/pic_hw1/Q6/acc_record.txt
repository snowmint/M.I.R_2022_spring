## Sum-up cqt chromagram as input
input shape: (12, 1)
result: val_loss: 89.4135 - val_accuracy: 0.3571
model structure:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 1, 12, 24)         624       
_________________________________________________________________
batch_normalization (BatchNo (None, 1, 12, 24)         96        
_________________________________________________________________
dropout (Dropout)            (None, 1, 12, 24)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 12, 24)         14424     
_________________________________________________________________
batch_normalization_1 (Batch (None, 1, 12, 24)         96        
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1, 12, 24)         14424     
_________________________________________________________________
batch_normalization_2 (Batch (None, 1, 12, 24)         96        
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1, 12, 24)         14424     
_________________________________________________________________
batch_normalization_3 (Batch (None, 1, 12, 24)         96        
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1, 12, 24)         14424     
_________________________________________________________________
batch_normalization_4 (Batch (None, 1, 12, 24)         96        


## Pick front 1000 frame as input
input shape: (12,1000)
result: loss: 2.9067 - accuracy: 0.4405
Model structure:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 12, 1000, 24)      624       
_________________________________________________________________
batch_normalization_6 (Batch (None, 12, 1000, 24)      96        
_________________________________________________________________
dropout_1 (Dropout)          (None, 12, 1000, 24)      0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 12, 1000, 24)      14424     
_________________________________________________________________
batch_normalization_7 (Batch (None, 12, 1000, 24)      96        
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 12, 1000, 24)      14424     
_________________________________________________________________
batch_normalization_8 (Batch (None, 12, 1000, 24)      96        
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 12, 1000, 24)      14424     
_________________________________________________________________
batch_normalization_9 (Batch (None, 12, 1000, 24)      96        
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 12, 1000, 24)      14424     
_________________________________________________________________
batch_normalization_10 (Batc (None, 12, 1000, 24)      96        


## madmom deep chromagram as input
input shape: (300, 12)
result: loss: 2.3609 - accuracy: 0.4611
model structure:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 300, 12, 24)       624       
_________________________________________________________________
batch_normalization (BatchNo (None, 300, 12, 24)       96        
_________________________________________________________________
dropout (Dropout)            (None, 300, 12, 24)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 300, 12, 24)       14424     
_________________________________________________________________
batch_normalization_1 (Batch (None, 300, 12, 24)       96        
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 300, 12, 24)       14424     
_________________________________________________________________
batch_normalization_2 (Batch (None, 300, 12, 24)       96        
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 300, 12, 24)       14424     
_________________________________________________________________
batch_normalization_3 (Batch (None, 300, 12, 24)       96        
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 300, 12, 24)       14424     
_________________________________________________________________
batch_normalization_4 (Batch (None, 300, 12, 24)       96        

## hybrid_cqt chromagram as input
input shape: (144, 150)
result: loss: 2.5343 - accuracy: 0.4671 
model structure:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 144, 150, 24)      624       
_________________________________________________________________
batch_normalization_6 (Batch (None, 144, 150, 24)      96        
_________________________________________________________________
dropout_1 (Dropout)          (None, 144, 150, 24)      0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 144, 150, 24)      14424     
_________________________________________________________________
batch_normalization_7 (Batch (None, 144, 150, 24)      96        
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 144, 150, 24)      14424     
_________________________________________________________________
batch_normalization_8 (Batch (None, 144, 150, 24)      96        
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 144, 150, 24)      14424     
_________________________________________________________________
batch_normalization_9 (Batch (None, 144, 150, 24)      96        
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 144, 150, 24)      14424     
_________________________________________________________________
batch_normalization_10 (Batc (None, 144, 150, 24)      96        

## Just 5 Dense layer as classifier with hybrid_cqt
input shape: (144, 150)
result: loss: 1.8019 - accuracy: 0.5179
- training_raw_accuracy         0.517143
- training_weighted_accuracy    0.577952
model structure:
layers.Dense(512, activation='relu')
layers.Dense(256, activation='elu')
layers.Dense(128, activation='elu')
layers.Dense(48, activation='elu')
layers.Dense(24, activation='softmax')


